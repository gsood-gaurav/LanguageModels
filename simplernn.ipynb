{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-29 20:46:35.785793: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-07-29 20:46:36.247606: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-29 20:46:38.081891: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext tensorboard\n",
    "# %tensorboard --logdir runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-29 20:46:41.073928: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-07-29 20:46:41.465426: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-07-29 20:46:41.465478: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-07-29 20:46:41.470374: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-07-29 20:46:41.470429: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-07-29 20:46:41.470449: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-07-29 20:46:43.693312: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-07-29 20:46:43.693481: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-07-29 20:46:43.693496: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1722] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-07-29 20:46:43.693539: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-07-29 20:46:43.694138: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2042 MB memory:  -> device: 0, name: NVIDIA T1200 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 7.5\n",
      "2023-07-29 20:46:44.145763: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-07-29 20:46:47.538164: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    }
   ],
   "source": [
    "def data_gen(file_names):\n",
    "    for file_name in file_names:\n",
    "        with open(file_name, 'r') as f:\n",
    "            xs, ys = [], []\n",
    "            for line in f:\n",
    "                line = line.strip()\n",
    "                if not line:\n",
    "                    yield (xs, ys)\n",
    "                    xs, ys = [], []\n",
    "                else:\n",
    "                    word, tag = line.split()\n",
    "                    xs.append(word)\n",
    "                    ys.append(tag)\n",
    "\n",
    "dataset = tf.data.Dataset.from_generator(\n",
    "    data_gen,\n",
    "    args = [(\"eng.train.iob\", \"eng.testa.iob\", \"eng.testb.iob\")],\n",
    "    output_signature= (\n",
    "        tf.TensorSpec(shape=(None,), dtype=tf.string),\n",
    "        tf.TensorSpec(shape=(None,), dtype=tf.string)\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# val_dataset = tf.data.Dataset.from_generator(\n",
    "#     data_gen,\n",
    "#     args = [\"eng.testa.iob\"],\n",
    "#     output_signature= (\n",
    "#         tf.TensorSpec(shape=(None,), dtype=tf.string),\n",
    "#         tf.TensorSpec(shape=(None,), dtype=tf.string)\n",
    "#     ))\n",
    "\n",
    "sentences = dataset.map(lambda xs, _ : xs)\n",
    "tags = dataset.map(lambda _, ys : ys)\n",
    "layer_sen = tf.keras.layers.TextVectorization(standardize=\"lower_and_strip_punctuation\")\n",
    "layer_tag = tf.keras.layers.TextVectorization(standardize=\"lower_and_strip_punctuation\", max_tokens=8)\n",
    "layer_sen.adapt(sentences)\n",
    "layer_tag.adapt(tags)\n",
    "# print(layer_sen.get_vocabulary())\n",
    "vocab_size = layer_sen.vocabulary_size()\n",
    "# print(vocab_size)\n",
    "num_tags = layer_tag.vocabulary_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.shuffle(1000, reshuffle_each_iteration=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '[UNK]', 'o', 'ius', 'iaa', 'bus', 'baa']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = layer_tag.get_vocabulary()\n",
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = dataset.map(lambda xs, ys: (xs, ys))\n",
    "data = dataset.map(lambda xs, ys: (tf.reshape(layer_sen(xs), tf.shape(xs)), tf.reshape(layer_tag(ys), tf.shape(ys)))).padded_batch(batch_size)\n",
    "# validation_dataset = val_dataset.map(lambda xs, ys: (tf.reshape(layer_sen(xs), tf.shape(xs)), tf.reshape(layer_tag(ys), tf.shape(ys)))).padded_batch(batch_size)\n",
    "# list(train_dataset.take(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-29 20:46:51.103899: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_10' with dtype int64\n",
      "\t [[{{node Placeholder/_10}}]]\n",
      "2023-07-29 20:46:51.104245: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_15' with dtype string\n",
      "\t [[{{node Placeholder/_15}}]]\n"
     ]
    }
   ],
   "source": [
    "DATASET_SIZE = len(list(data))\n",
    "TRAIN_SIZE = int(0.8 * DATASET_SIZE)\n",
    "VAL_SIZE = DATASET_SIZE - TRAIN_SIZE\n",
    "\n",
    "train_data = data.take(TRAIN_SIZE)\n",
    "val_data = data.skip(VAL_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-29 20:48:59.217368: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-07-29 20:49:01.809806: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis' with dtype int32 and shape [1]\n",
      "\t [[{{node gradients/ReverseV2_grad/ReverseV2/ReverseV2/axis}}]]\n",
      "2023-07-29 20:49:03.001325: W tensorflow/core/common_runtime/type_inference.cc:339] Type inference failed. This indicates an invalid graph that escaped type checking. Error message: INVALID_ARGUMENT: expected compatible input types, but input 1:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_INT32\n",
      "    }\n",
      "  }\n",
      "}\n",
      " is neither a subtype nor a supertype of the combined inputs preceding it:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\twhile inferring type of node 'cond_42/output/_24'\n",
      "2023-07-29 20:49:05.671611: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600\n",
      "2023-07-29 20:49:06.077918: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f6ed8035b00 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-07-29 20:49:06.077982: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA T1200 Laptop GPU, Compute Capability 7.5\n",
      "2023-07-29 20:49:06.250822: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-07-29 20:49:07.582372: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    515/Unknown - 128s 226ms/step - loss: 0.4385"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-29 20:51:05.431122: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_11' with dtype string\n",
      "\t [[{{node Placeholder/_11}}]]\n",
      "2023-07-29 20:51:05.431504: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_14' with dtype int64\n",
      "\t [[{{node Placeholder/_14}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "516/516 [==============================] - 144s 256ms/step - loss: 0.4384 - val_loss: 0.2932\n",
      "Epoch 2/20\n",
      "516/516 [==============================] - 105s 203ms/step - loss: 0.2807 - val_loss: 0.2200\n",
      "Epoch 3/20\n",
      "516/516 [==============================] - 114s 222ms/step - loss: 0.2264 - val_loss: 0.1782\n",
      "Epoch 4/20\n",
      "516/516 [==============================] - 111s 210ms/step - loss: 0.1855 - val_loss: 0.1571\n",
      "Epoch 5/20\n",
      "516/516 [==============================] - 108s 209ms/step - loss: 0.1609 - val_loss: 0.1412\n",
      "Epoch 6/20\n",
      "516/516 [==============================] - 102s 197ms/step - loss: 0.1521 - val_loss: 0.1305\n",
      "Epoch 7/20\n",
      "516/516 [==============================] - 104s 200ms/step - loss: 0.1349 - val_loss: 0.1174\n",
      "Epoch 8/20\n",
      "516/516 [==============================] - 104s 201ms/step - loss: 0.1280 - val_loss: 0.1326\n",
      "Epoch 9/20\n",
      "516/516 [==============================] - 107s 208ms/step - loss: 0.1063 - val_loss: 0.1049\n",
      "Epoch 10/20\n",
      "516/516 [==============================] - 98s 190ms/step - loss: 0.1088 - val_loss: 0.0998\n",
      "Epoch 11/20\n",
      "516/516 [==============================] - 106s 205ms/step - loss: 0.1064 - val_loss: 0.0839\n",
      "Epoch 12/20\n",
      "516/516 [==============================] - 96s 186ms/step - loss: 0.1072 - val_loss: 0.0819\n",
      "Epoch 13/20\n",
      "516/516 [==============================] - 108s 210ms/step - loss: 0.0958 - val_loss: 0.0934\n",
      "Epoch 14/20\n",
      "516/516 [==============================] - 102s 198ms/step - loss: 0.0910 - val_loss: 0.0824\n",
      "Epoch 15/20\n",
      "516/516 [==============================] - 103s 200ms/step - loss: 0.0874 - val_loss: 0.0711\n",
      "Epoch 16/20\n",
      "516/516 [==============================] - 98s 186ms/step - loss: 0.0785 - val_loss: 0.0734\n",
      "Epoch 17/20\n",
      "516/516 [==============================] - 102s 198ms/step - loss: 0.0906 - val_loss: 0.0823\n",
      "Epoch 18/20\n",
      "516/516 [==============================] - 102s 197ms/step - loss: 0.0852 - val_loss: 0.0823\n",
      "Epoch 19/20\n",
      "516/516 [==============================] - 100s 193ms/step - loss: 0.0880 - val_loss: 0.0866\n",
      "Epoch 20/20\n",
      "516/516 [==============================] - 104s 201ms/step - loss: 0.0905 - val_loss: 0.0732\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6f6a9c6150>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class EncoderLSTM(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
    "        super(EncoderLSTM, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.enc_units = enc_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim, mask_zero=True)\n",
    "        self.lstm = tf.keras.layers.LSTM(self.enc_units, return_sequences=True)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.embedding(x)\n",
    "        output = self.lstm(x)\n",
    "\n",
    "        return output\n",
    "    \n",
    "\n",
    "class DecoderLSTM(tf.keras.layers.Layer):\n",
    "\n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "        super(DecoderLSTM, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.dec_units = dec_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim, mask_zero=True)\n",
    "        self.lstm = tf.keras.layers.LSTM(self.dec_units, return_sequences=True)\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "    def call(self, x, hidden):\n",
    "        x = self.embedding(x)\n",
    "        output = self.lstm(x, initial_state = hidden)\n",
    "        output = self.fc(output)\n",
    "\n",
    "        return output\n",
    "                                                   \n",
    "\n",
    "class MyModel(tf.keras.Model):\n",
    "    def __init__(self, vocab_size=vocab_size, num_tags=num_tags):\n",
    "        super().__init__()\n",
    "        # self.minput = tf.keras.Input(type_spec=tf.TensorSpec(shape=(None, None), dtype=tf.int32))\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size+1, 32, mask_zero=True)\n",
    "        self.lstm = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(32, return_sequences=True))\n",
    "        self.layer_norm = tf.keras.layers.LayerNormalization()\n",
    "        # self.dropout1 = tf.keras.layers.Dropout(0.5)\n",
    "        self.dense1 = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(16, activation='relu'))\n",
    "        # self.dropout2 = tf.keras.layers.Dropout(0.5)\n",
    "        self.dense2 = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(num_tags, activation=\"softmax\"))\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # x = self.minput(inputs)\n",
    "        x = self.embedding(inputs)\n",
    "        x = self.lstm(x)\n",
    "        x = self.layer_norm(x)\n",
    "        # x = self.dropout1(x)\n",
    "        x = self.dense1(x)\n",
    "        # x = self.dropout2(x)\n",
    "        x = self.dense2(x)\n",
    "        return x\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = nll(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_mean(loss_)\n",
    "\n",
    "\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "nll = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
    "\n",
    "model = MyModel(vocab_size=vocab_size, num_tags=num_tags)\n",
    "model.compile(loss=loss_function, optimizer=optimizer)\n",
    "model.fit(train_data, epochs=20, validation_data=val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 46ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 1), dtype=int64, numpy=\n",
       "array([[5],\n",
       "       [6],\n",
       "       [5]])>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(layer_sen(\"Unable to print\".split()))\n",
    "# predictions = model.predict(tf.constant([[282, 12]]))\n",
    "# tf.keras.activations.softmax(predictions)\n",
    "tf.argmax(predictions, axis=-1)\n",
    "# tf.keras.activations.softmax(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bus baa bus'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = layer_tag.get_vocabulary()\n",
    "\" \".join([vocab[each] for each in tf.squeeze(tf.argmax(predictions, axis=-1))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
